const fs = require('fs');
const path = require('path');

const inputFile = path.join(__dirname, '../ouycwnsb_db.sql');
const outputFile = path.join(__dirname, '../final_migration.sql');

if (!fs.existsSync(inputFile)) {
    console.error('Input file not found:', inputFile);
    process.exit(1);
}

const sqlContent = fs.readFileSync(inputFile, 'utf8');
const lines = sqlContent.split('\n');

const userMapel = {}; // userId -> [mapel]
const userKelas = {}; // userId -> [kelas]

// First pass: Collect pivot data
// In this pass, we just need to identify lines that are part of user_mapel or user_kelas inserts
let currentPivotTable = null;

lines.forEach(line => {
    let trimmed = line.trim();
    if (trimmed.startsWith("INSERT INTO `user_mapel`")) currentPivotTable = 'user_mapel';
    else if (trimmed.startsWith("INSERT INTO `user_kelas`")) currentPivotTable = 'user_kelas';
    else if (trimmed.startsWith("INSERT INTO")) currentPivotTable = null;
    else if (trimmed.endsWith(";")) {
        // Process final line of a block
        if (currentPivotTable) processPivotLine(line, currentPivotTable);
        currentPivotTable = null;
    } else if (currentPivotTable) {
        processPivotLine(line, currentPivotTable);
    }
});

function processPivotLine(line, table) {
    // Line format: ('uid', 'val'), or ('uid', 'val');
    // We can just regex match all ('x', 'y') pairs
    const matches = line.match(/\('([^']*)', '([^']*)'\)/g);
    if (!matches) return;

    matches.forEach(m => {
        const parts = m.match(/'([^']*)'/g);
        if (parts && parts.length === 2) {
            const uid = parts[0].replace(/'/g, '');
            const val = parts[1].replace(/'/g, '');
            if (table === 'user_mapel') {
                if (!userMapel[uid]) userMapel[uid] = [];
                if (!userMapel[uid].includes(val)) userMapel[uid].push(val);
            } else {
                if (!userKelas[uid]) userKelas[uid] = [];
                if (!userKelas[uid].includes(val)) userKelas[uid].push(val);
            }
        }
    });
}


let outputSQL = "-- Migration Script generated by Antigravity\n";
outputSQL += "-- Target Database: MySQL (mgmp-v2)\n\n";

// Ensure tables have correct columns
outputSQL += "ALTER TABLE profiles ADD COLUMN IF NOT EXISTS email VARCHAR(255);\n";
outputSQL += "ALTER TABLE profiles ADD COLUMN IF NOT EXISTS password_hash VARCHAR(255);\n";
outputSQL += "ALTER TABLE profiles ADD COLUMN IF NOT EXISTS mapel TEXT; -- JSON\n";
outputSQL += "ALTER TABLE profiles ADD COLUMN IF NOT EXISTS kelas TEXT; -- JSON\n";
outputSQL += "ALTER TABLE profiles ADD COLUMN IF NOT EXISTS subscription_status VARCHAR(50);\n";
outputSQL += "ALTER TABLE events ADD COLUMN IF NOT EXISTS updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP;\n\n";


let currentTable = null;
let insertHeader = "";

for (let i = 0; i < lines.length; i++) {
    let line = lines[i].trim();
    if (!line) continue;

    if (line.startsWith("INSERT INTO `users`")) {
        currentTable = 'users'; // Start processing users
        // Use custom INSERT header for profiles
        outputSQL += `INSERT INTO \`profiles\` (id, nama, email, password_hash, role, is_active, asal_sekolah, pendidikan_terakhir, jurusan, status_kepegawaian, ukuran_baju, no_hp, foto_profile, subscription_status, mapel, kelas, created_at, updated_at) VALUES\n`;

        // Process the values part on the same line if exists
        const valuesIdx = line.indexOf('VALUES');
        if (valuesIdx !== -1) {
            const remainder = line.substring(valuesIdx + 6).trim();
            if (remainder) processUserValues(remainder);
        }
    }
    else if (line.startsWith("INSERT INTO `events`")) {
        currentTable = 'events';
        // Add updated_at to column list if missing (it IS missing in source)
        // Source: (`id`, ..., `certificate_template`)
        // Reconstruct header with updated_at
        // Or honestly, just use the source header but replace columns
        let header = line.substring(0, line.indexOf('VALUES'));
        header = header.replace("`certificateUrl`", "`certificate_url`");
        outputSQL += header + " VALUES\n";

        const valuesIdx = line.indexOf('VALUES');
        if (valuesIdx !== -1) {
            const remainder = line.substring(valuesIdx + 6).trim();
            if (remainder) outputSQL += remainder + "\n"; // Just dump it
        }
    }
    else if (line.startsWith("INSERT INTO `subscriptions`")) {
        currentTable = 'subscriptions';
        // Source: (`id`, `user_id`, `proof_image`, `status`, `start_date`, `end_date`, `created_at`)
        // Target: premium_subscriptions (id, user_id, payment_proof_url, status, start_date, end_date, created_at)
        let header = "INSERT INTO `premium_subscriptions` (`id`, `user_id`, `payment_proof_url`, `status`, `start_date`, `end_date`, `created_at`)";
        outputSQL += header + " VALUES\n";

        const valuesIdx = line.indexOf('VALUES');
        if (valuesIdx !== -1) {
            const remainder = line.substring(valuesIdx + 6).trim();
            if (remainder) outputSQL += remainder + "\n";
        }
    }
    else if (line.startsWith("INSERT INTO `event_participants`") || line.startsWith("INSERT INTO `site_content`") || line.startsWith("INSERT INTO `learning_references`")) {
        currentTable = 'copy';
        outputSQL += line + "\n";
    }
    else if (line.startsWith("INSERT INTO")) {
        currentTable = null; // Ignore other tables
    }
    else if (currentTable) {
        // Continuation lines
        if (currentTable === 'users') {
            processUserValues(line);
        } else if (currentTable === 'events') {
            outputSQL += line + "\n";
        } else if (currentTable === 'subscriptions') {
            outputSQL += line + "\n";
        } else if (currentTable === 'copy') {
            outputSQL += line + "\n";
        }

        if (line.endsWith(';')) {
            currentTable = null;
            outputSQL += "\n";
        }
    }
}

function processUserValues(line) {
    // line is like: ('uuid', 'name', ...), or ('uuid', 'name', ...);
    // Regex extract rows
    // This simple splitter logic `\),\s*\(` is dangerous if text contains "), ("
    // But for this dump assuming standard escaping

    // Actually, we can just process row by row if the dump is formatted nicely (one row per line)
    // Looking at the view_file, it IS one row per line starting with (

    if (!line.startsWith('(')) return; // Skip garbage

    // Clean trailing comma or semicolon
    let cleanLine = line.replace(/[,;]$/, '');

    // Parse columns: 'val', 'val', NULL, ...
    // Matches: 'string' OR NULL OR number
    const colsMatch = cleanLine.match(/('((?:[^'\\]|\\.)*)'|NULL|[\d\.-]+)/g);

    if (colsMatch && colsMatch.length >= 16) {
        const id = colsMatch[0].replace(/'/g, '');

        const mapelVal = userMapel[id] ? `'${JSON.stringify(userMapel[id])}'` : "NULL";
        const kelasVal = userKelas[id] ? `'${JSON.stringify(userKelas[id])}'` : "NULL";

        // Construct new row
        // 0:id, 1:nama, 2:email, 3:pass, 4:asal, 5:pend, 6:jur, 7:status, 8:role, 9:active, 10:created, 11:updated, 12:ukuran, 13:hp, 14:foto, 15:sub

        const newRow = `(${colsMatch[0]}, ${colsMatch[1]}, ${colsMatch[2]}, ${colsMatch[3]}, ${colsMatch[8]}, ${colsMatch[9]}, ${colsMatch[4]}, ${colsMatch[5]}, ${colsMatch[6]}, ${colsMatch[7]}, ${colsMatch[12]}, ${colsMatch[13]}, ${colsMatch[14]}, ${colsMatch[15]}, ${mapelVal}, ${kelasVal}, ${colsMatch[10]}, ${colsMatch[11]})`;

        outputSQL += newRow + (line.endsWith(';') ? ';' : ',') + "\n";
    }
}

fs.writeFileSync(outputFile, outputSQL);
console.log('Migration script generated:', outputFile);
